{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# å› å­åˆ†æç¤ºä¾‹\n",
        "\n",
        "è¿™ä¸ªç¬”è®°æœ¬æ¼”ç¤ºäº†å¦‚ä½•åŠ è½½è‚¡ç¥¨æ•°æ®ï¼Œè®¡ç®—å› å­ICå€¼ï¼Œå¹¶åˆ†æå› å­å¯¹æœªæ¥æ”¶ç›Šçš„é¢„æµ‹èƒ½åŠ›ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# è®¾ç½®ç»˜å›¾æ ·å¼\n",
        "plt.style.use('ggplot')\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. ä»Excelæ–‡ä»¶åŠ è½½æ•°æ®\n",
        "\n",
        "æˆ‘ä»¬å°†ä»Excelæ–‡ä»¶åŠ è½½è‚¡ç¥¨æ•°æ®ï¼Œè¯¥æ–‡ä»¶åŒ…å«è‚¡ç¥¨ä»£ç ã€æ—¥æœŸå’Œå„ç§æŠ€æœ¯æŒ‡æ ‡ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åŠ è½½Excelæ•°æ®\n",
        "def load_data_from_excel(file_path):\n",
        "    \"\"\"ä»Excelæ–‡ä»¶åŠ è½½æ•°æ®ï¼Œè‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ä»£ç åˆ—å’Œæ—¥æœŸåˆ—\"\"\"\n",
        "    try:\n",
        "        # è¯»å–Excelæ–‡ä»¶\n",
        "        df = pd.read_excel(file_path)\n",
        "        \n",
        "        # æ˜¾ç¤ºåˆ—åï¼Œå¸®åŠ©è¯†åˆ«\n",
        "        print(\"Excelæ–‡ä»¶åˆ—åï¼š\")\n",
        "        for col in df.columns:\n",
        "            print(f\"- {col}\")\n",
        "        \n",
        "        # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ä»£ç åˆ—å’Œæ—¥æœŸåˆ—\n",
        "        date_col = None\n",
        "        code_col = None\n",
        "        \n",
        "        for col in df.columns:\n",
        "            col_lower = str(col).lower()\n",
        "            # è¯†åˆ«æ—¥æœŸåˆ—\n",
        "            if any(keyword in col_lower for keyword in ['date', 'æ—¥æœŸ', 'time', 'æ—¶é—´']):\n",
        "                date_col = col\n",
        "            # è¯†åˆ«è‚¡ç¥¨ä»£ç åˆ—\n",
        "            elif any(keyword in col_lower for keyword in ['code', 'ä»£ç ', 'stock', 'è‚¡ç¥¨', 'ticker', 'symbol']):\n",
        "                code_col = col\n",
        "        \n",
        "        if date_col is None or code_col is None:\n",
        "            print(\"è­¦å‘Šï¼šæ— æ³•è‡ªåŠ¨è¯†åˆ«æ—¥æœŸåˆ—æˆ–è‚¡ç¥¨ä»£ç åˆ—ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š\")\n",
        "            return df, None, None\n",
        "        \n",
        "        print(f\"è¯†åˆ«åˆ°çš„æ—¥æœŸåˆ—: {date_col}\")\n",
        "        print(f\"è¯†åˆ«åˆ°çš„è‚¡ç¥¨ä»£ç åˆ—: {code_col}\")\n",
        "        \n",
        "        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯æ—¥æœŸç±»å‹\n",
        "        df[date_col] = pd.to_datetime(df[date_col])\n",
        "        \n",
        "        return df, date_col, code_col\n",
        "    except Exception as e:\n",
        "        print(f\"åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# åŠ è½½ç¤ºä¾‹æ•°æ®\n",
        "file_path = \"å› å­åˆ†ææ¨¡ç‰ˆ.xlsx\"  # è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®\n",
        "data, date_col, code_col = load_data_from_excel(file_path)\n",
        "\n",
        "if data is not None:\n",
        "    # æ˜¾ç¤ºæ•°æ®å‰å‡ è¡Œ\n",
        "    display(data.head())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. æ•°æ®é¢„å¤„ç†\n",
        "\n",
        "æˆ‘ä»¬éœ€è¦è®¡ç®—æœªæ¥æ”¶ç›Šç‡å¹¶å‡†å¤‡å› å­æ•°æ®ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_factor_data(df, date_col, code_col, forward_days=1):\n",
        "    \"\"\"å‡†å¤‡å› å­åˆ†ææ•°æ®ï¼Œè®¡ç®—æœªæ¥æ”¶ç›Šç‡\"\"\"\n",
        "    if df is None or date_col is None or code_col is None:\n",
        "        print(\"æ•°æ®æˆ–åˆ—åæœªæ­£ç¡®åŠ è½½\")\n",
        "        return None\n",
        "    \n",
        "    # å¤åˆ¶æ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®\n",
        "    data = df.copy()\n",
        "    \n",
        "    # è¯†åˆ«å¯èƒ½çš„ä»·æ ¼åˆ—\n",
        "    price_cols = []\n",
        "    for col in data.columns:\n",
        "        col_lower = str(col).lower()\n",
        "        if any(keyword in col_lower for keyword in ['price', 'ä»·æ ¼', 'close', 'æ”¶ç›˜']):\n",
        "            price_cols.append(col)\n",
        "    \n",
        "    if not price_cols:\n",
        "        print(\"è­¦å‘Šï¼šæœªæ‰¾åˆ°ä»·æ ¼åˆ—ï¼Œæ— æ³•è®¡ç®—æœªæ¥æ”¶ç›Šç‡\")\n",
        "        return None\n",
        "    \n",
        "    price_col = price_cols[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ä»·æ ¼åˆ—\n",
        "    print(f\"ä½¿ç”¨ '{price_col}' åˆ—è®¡ç®—æœªæ¥æ”¶ç›Šç‡\")\n",
        "    \n",
        "    # æŒ‰è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸæ’åº\n",
        "    data = data.sort_values([code_col, date_col])\n",
        "    \n",
        "    # è®¡ç®—æœªæ¥æ”¶ç›Šç‡\n",
        "    data['future_return'] = data.groupby(code_col)[price_col].pct_change(forward_days).shift(-forward_days)\n",
        "    \n",
        "    # è¯†åˆ«å› å­åˆ—ï¼ˆæ’é™¤æ—¥æœŸã€ä»£ç ã€ä»·æ ¼å’Œæœªæ¥æ”¶ç›Šåˆ—ï¼‰\n",
        "    factor_cols = [col for col in data.columns if col not in [date_col, code_col, price_col, 'future_return']]\n",
        "    \n",
        "    print(f\"è¯†åˆ«åˆ°çš„å› å­åˆ—: {len(factor_cols)}ä¸ª\")\n",
        "    if len(factor_cols) > 0:\n",
        "        print(f\"å‰5ä¸ªå› å­: {factor_cols[:5]}\")\n",
        "    \n",
        "    # åˆ é™¤ç¼ºå¤±å€¼\n",
        "    data = data.dropna(subset=['future_return'] + factor_cols)\n",
        "    \n",
        "    return data, factor_cols\n",
        "\n",
        "# å‡†å¤‡å› å­æ•°æ®\n",
        "processed_data, factor_cols = prepare_factor_data(data, date_col, code_col, forward_days=1)\n",
        "\n",
        "if processed_data is not None:\n",
        "    print(f\"\\nå¤„ç†åçš„æ•°æ®å½¢çŠ¶: {processed_data.shape}\")\n",
        "    display(processed_data.head())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. è®¡ç®—å› å­ICå€¼\n",
        "\n",
        "ICï¼ˆInformation Coefficientï¼‰æ˜¯è¡¡é‡å› å­é¢„æµ‹èƒ½åŠ›çš„é‡è¦æŒ‡æ ‡ï¼Œå®ƒè®¡ç®—å› å­å€¼ä¸æœªæ¥æ”¶ç›Šä¹‹é—´çš„ç›¸å…³æ€§ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_ic(data, factor_cols, date_col):\n",
        "    \"\"\"è®¡ç®—æ¯ä¸ªå› å­çš„ICå€¼\"\"\"\n",
        "    if data is None or not factor_cols:\n",
        "        print(\"æ•°æ®æˆ–å› å­åˆ—æœªæ­£ç¡®åŠ è½½\")\n",
        "        return None\n",
        "    \n",
        "    # å­˜å‚¨æ¯ä¸ªå› å­çš„ICå€¼\n",
        "    ic_dict = {}\n",
        "    \n",
        "    # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—IC\n",
        "    for factor in factor_cols:\n",
        "        # è®¡ç®—æ¯ä¸ªæ—¥æœŸçš„ICå€¼\n",
        "        daily_ic = data.groupby(date_col).apply(\n",
        "            lambda x: x[factor].corr(x['future_return'], method='spearman')\n",
        "        )\n",
        "        \n",
        "        # è®¡ç®—å¹³å‡IC\n",
        "        avg_ic = daily_ic.mean()\n",
        "        ic_dict[factor] = {\n",
        "            'avg_ic': avg_ic,\n",
        "            'ic_series': daily_ic\n",
        "        }\n",
        "    \n",
        "    # åˆ›å»ºICæ‘˜è¦DataFrame\n",
        "    ic_summary = pd.DataFrame({\n",
        "        'factor': list(ic_dict.keys()),\n",
        "        'avg_ic': [ic_dict[f]['avg_ic'] for f in ic_dict]\n",
        "    })\n",
        "    \n",
        "    # æŒ‰å¹³å‡ICå€¼æ’åº\n",
        "    ic_summary = ic_summary.sort_values('avg_ic', ascending=False)\n",
        "    \n",
        "    return ic_summary, ic_dict\n",
        "\n",
        "# è®¡ç®—ICå€¼\n",
        "ic_summary, ic_dict = calculate_ic(processed_data, factor_cols, date_col)\n",
        "\n",
        "if ic_summary is not None:\n",
        "    print(\"å› å­ICå€¼æ‘˜è¦ï¼ˆæŒ‰ICå€¼é™åºæ’åˆ—ï¼‰ï¼š\")\n",
        "    display(ic_summary)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. å¯è§†åŒ–å› å­ICå€¼\n",
        "\n",
        "æˆ‘ä»¬å°†ç»˜åˆ¶å› å­ICå€¼çš„æŸ±çŠ¶å›¾ï¼Œä»¥ç›´è§‚åœ°æ¯”è¾ƒä¸åŒå› å­çš„é¢„æµ‹èƒ½åŠ›ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_ic_bars(ic_summary, top_n=10):\n",
        "    \"\"\"ç»˜åˆ¶å› å­ICå€¼çš„æŸ±çŠ¶å›¾\"\"\"\n",
        "    if ic_summary is None or len(ic_summary) == 0:\n",
        "        print(\"æ²¡æœ‰ICå€¼æ•°æ®å¯ä¾›ç»˜å›¾\")\n",
        "        return\n",
        "    \n",
        "    # é€‰æ‹©å‰Nä¸ªå’ŒåNä¸ªå› å­\n",
        "    top_factors = ic_summary.head(top_n)\n",
        "    bottom_factors = ic_summary.tail(top_n)\n",
        "    \n",
        "    # åˆå¹¶ä¸ºä¸€ä¸ªDataFrame\n",
        "    plot_data = pd.concat([top_factors, bottom_factors])\n",
        "    \n",
        "    # ç»˜åˆ¶æŸ±çŠ¶å›¾\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    bars = plt.bar(plot_data['factor'], plot_data['avg_ic'])\n",
        "    \n",
        "    # ä¸ºæ­£è´ŸICå€¼è®¾ç½®ä¸åŒé¢œè‰²\n",
        "    for i, bar in enumerate(bars):\n",
        "        if plot_data['avg_ic'].iloc[i] > 0:\n",
        "            bar.set_color('green')\n",
        "        else:\n",
        "            bar.set_color('red')\n",
        "    \n",
        "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    plt.title(f'Top {top_n} and Bottom {top_n} Factors by IC Value', fontsize=14)\n",
        "    plt.xlabel('Factor')\n",
        "    plt.ylabel('Average IC')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ç»˜åˆ¶ICå€¼æŸ±çŠ¶å›¾\n",
        "plot_ic_bars(ic_summary, top_n=10)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. å› å­åˆ†ç»„åˆ†æ\n",
        "\n",
        "æˆ‘ä»¬å°†è‚¡ç¥¨æŒ‰å› å­å€¼åˆ†ç»„ï¼Œåˆ†æä¸åŒåˆ†ç»„çš„æœªæ¥æ”¶ç›Šè¡¨ç°ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def factor_quantile_analysis(data, factor, date_col, n_quantiles=5):\n",
        "    \"\"\"æŒ‰å› å­å€¼å°†è‚¡ç¥¨åˆ†ç»„ï¼Œåˆ†æå„ç»„çš„æœªæ¥æ”¶ç›Š\"\"\"\n",
        "    if data is None:\n",
        "        print(\"æ²¡æœ‰æ•°æ®å¯ä¾›åˆ†æ\")\n",
        "        return None\n",
        "    \n",
        "    # å¤åˆ¶æ•°æ®\n",
        "    df = data.copy()\n",
        "    \n",
        "    # æŒ‰æ—¥æœŸåˆ†ç»„ï¼Œè®¡ç®—å› å­åˆ†ä½æ•°\n",
        "    df['quantile'] = df.groupby(date_col)[factor].transform(\n",
        "        lambda x: pd.qcut(x, n_quantiles, labels=False, duplicates='drop')\n",
        "    )\n",
        "    \n",
        "    # è®¡ç®—æ¯ä¸ªåˆ†ä½æ•°çš„å¹³å‡æœªæ¥æ”¶ç›Š\n",
        "    quantile_returns = df.groupby(['quantile', date_col])['future_return'].mean().reset_index()\n",
        "    avg_returns = quantile_returns.groupby('quantile')['future_return'].mean()\n",
        "    \n",
        "    return avg_returns\n",
        "\n",
        "# é€‰æ‹©ICå€¼æœ€é«˜çš„å› å­è¿›è¡Œåˆ†ç»„åˆ†æ\n",
        "if ic_summary is not None and len(ic_summary) > 0:\n",
        "    top_factor = ic_summary.iloc[0]['factor']\n",
        "    print(f\"å¯¹ICå€¼æœ€é«˜çš„å› å­è¿›è¡Œåˆ†ç»„åˆ†æ: {top_factor}\")\n",
        "    \n",
        "    quantile_returns = factor_quantile_analysis(processed_data, top_factor, date_col)\n",
        "    \n",
        "    if quantile_returns is not None:\n",
        "        # ç»˜åˆ¶åˆ†ä½æ•°æ”¶ç›Šå›¾\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        quantile_returns.plot(kind='bar')\n",
        "        plt.title(f'{top_factor} Factor Quantile Returns', fontsize=14)\n",
        "        plt.xlabel('Quantile (0 = Lowest Factor Value, 4 = Highest)')\n",
        "        plt.ylabel('Average Future Return')\n",
        "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. å¤šå› å­ç»„åˆ\n",
        "\n",
        "æˆ‘ä»¬å¯ä»¥ç»“åˆå¤šä¸ªå› å­åˆ›å»ºä¸€ä¸ªç»¼åˆå› å­ï¼Œä»¥æé«˜é¢„æµ‹èƒ½åŠ›ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_multi_factor(data, factor_cols, ic_summary, top_n=5):\n",
        "    \"\"\"åˆ›å»ºå¤šå› å­ç»„åˆ\"\"\"\n",
        "    if data is None or ic_summary is None:\n",
        "        print(\"æ•°æ®æˆ–ICæ‘˜è¦æœªæ­£ç¡®åŠ è½½\")\n",
        "        return None\n",
        "    \n",
        "    # é€‰æ‹©ICå€¼æœ€é«˜çš„Nä¸ªå› å­\n",
        "    top_factors = ic_summary.head(top_n)['factor'].tolist()\n",
        "    print(f\"é€‰æ‹©çš„é¡¶çº§å› å­: {top_factors}\")\n",
        "    \n",
        "    # å¤åˆ¶æ•°æ®\n",
        "    df = data.copy()\n",
        "    \n",
        "    # æ ‡å‡†åŒ–å› å­å€¼\n",
        "    for factor in top_factors:\n",
        "        df[f'{factor}_zscore'] = df.groupby(date_col)[factor].transform(lambda x: (x - x.mean()) / x.std())\n",
        "    \n",
        "    # æ ¹æ®ICå€¼çš„ç¬¦å·è°ƒæ•´å› å­æ–¹å‘\n",
        "    weights = {}\n",
        "    for factor in top_factors:\n",
        "        ic_value = ic_summary[ic_summary['factor'] == factor]['avg_ic'].values[0]\n",
        "        # å¦‚æœICä¸ºè´Ÿï¼Œåˆ™åè½¬å› å­æ–¹å‘\n",
        "        weights[factor] = np.sign(ic_value)\n",
        "    \n",
        "    # åˆ›å»ºç»¼åˆå› å­\n",
        "    df['multi_factor'] = 0\n",
        "    for factor in top_factors:\n",
        "        df['multi_factor'] += df[f'{factor}_zscore'] * weights[factor]\n",
        "    \n",
        "    return df\n",
        "\n",
        "# åˆ›å»ºå¤šå› å­ç»„åˆ\n",
        "if ic_summary is not None and len(ic_summary) >= 5:\n",
        "    multi_factor_data = create_multi_factor(processed_data, factor_cols, ic_summary, top_n=5)\n",
        "    \n",
        "    if multi_factor_data is not None:\n",
        "        # è®¡ç®—å¤šå› å­çš„ICå€¼\n",
        "        multi_factor_ic = multi_factor_data.groupby(date_col).apply(\n",
        "            lambda x: x['multi_factor'].corr(x['future_return'], method='spearman')\n",
        "        ).mean()\n",
        "        \n",
        "        print(f\"å¤šå› å­ç»„åˆçš„å¹³å‡ICå€¼: {multi_factor_ic:.4f}\")\n",
        "        \n",
        "        # è¿›è¡Œåˆ†ç»„åˆ†æ\n",
        "        quantile_returns = factor_quantile_analysis(multi_factor_data, 'multi_factor', date_col)\n",
        "        \n",
        "        if quantile_returns is not None:\n",
        "            # ç»˜åˆ¶åˆ†ä½æ•°æ”¶ç›Šå›¾\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            quantile_returns.plot(kind='bar')\n",
        "            plt.title('Multi-Factor Quantile Returns', fontsize=14)\n",
        "            plt.xlabel('Quantile (0 = Lowest Factor Value, 4 = Highest)')\n",
        "            plt.ylabel('Average Future Return')\n",
        "            plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. å› å­ICç¨³å®šæ€§åˆ†æ\n",
        "\n",
        "åˆ†æå› å­ICå€¼éšæ—¶é—´çš„å˜åŒ–ï¼Œè¯„ä¼°å› å­çš„ç¨³å®šæ€§ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_ic_stability(ic_dict, top_n=3):\n",
        "    \"\"\"åˆ†æé¡¶çº§å› å­çš„ICç¨³å®šæ€§\"\"\"\n",
        "    if ic_dict is None or not ic_dict:\n",
        "        print(\"æ²¡æœ‰ICæ•°æ®å¯ä¾›åˆ†æ\")\n",
        "        return\n",
        "    \n",
        "    # é€‰æ‹©ICå€¼æœ€é«˜çš„Nä¸ªå› å­\n",
        "    top_factors = ic_summary.head(top_n)['factor'].tolist()\n",
        "    \n",
        "    # åˆ›å»ºICæ—¶é—´åºåˆ—DataFrame\n",
        "    ic_ts_data = {factor: ic_dict[factor]['ic_series'] for factor in top_factors}\n",
        "    ic_ts_df = pd.DataFrame(ic_ts_data)\n",
        "    \n",
        "    # ç»˜åˆ¶ICæ—¶é—´åºåˆ—\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    for factor in top_factors:\n",
        "        plt.plot(ic_ts_df.index, ic_ts_df[factor], label=factor)\n",
        "    \n",
        "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    plt.title('Factor IC Time Series', fontsize=14)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('IC Value')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # è®¡ç®—ICç¨³å®šæ€§æŒ‡æ ‡\n",
        "    ic_stats = {}\n",
        "    for factor in top_factors:\n",
        "        ic_series = ic_ts_df[factor].dropna()\n",
        "        ic_stats[factor] = {\n",
        "            'mean': ic_series.mean(),\n",
        "            'std': ic_series.std(),\n",
        "            'ir': ic_series.mean() / ic_series.std() if ic_series.std() > 0 else 0,\n",
        "            'positive_ratio': (ic_series > 0).mean()\n",
        "        }\n",
        "    \n",
        "    # åˆ›å»ºç»Ÿè®¡æ‘˜è¦DataFrame\n",
        "    stats_df = pd.DataFrame(ic_stats).T\n",
        "    stats_df.columns = ['å¹³å‡IC', 'æ ‡å‡†å·®', 'IRæ¯”ç‡', 'ICä¸ºæ­£çš„æ¯”ä¾‹']\n",
        "    \n",
        "    return stats_df\n",
        "\n",
        "# åˆ†æICç¨³å®šæ€§\n",
        "if ic_dict is not None and ic_summary is not None and len(ic_summary) >= 3:\n",
        "    ic_stability_stats = analyze_ic_stability(ic_dict, top_n=3)\n",
        "    \n",
        "    if ic_stability_stats is not None:\n",
        "        print(\"å› å­ICç¨³å®šæ€§ç»Ÿè®¡ï¼š\")\n",
        "        display(ic_stability_stats)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. æ€»ç»“\n",
        "\n",
        "é€šè¿‡ä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š\n",
        "\n",
        "1. æˆ‘ä»¬ä»Excelæ–‡ä»¶åŠ è½½äº†è‚¡ç¥¨æ•°æ®ï¼Œå¹¶è‡ªåŠ¨è¯†åˆ«äº†è‚¡ç¥¨ä»£ç ã€æ—¥æœŸå’Œå› å­åˆ—ã€‚\n",
        "2. æˆ‘ä»¬è®¡ç®—äº†æ¯ä¸ªå› å­çš„ICå€¼ï¼Œå¹¶æ‰¾å‡ºäº†é¢„æµ‹èƒ½åŠ›æœ€å¼ºçš„å› å­ã€‚\n",
        "3. æˆ‘ä»¬è¿›è¡Œäº†åˆ†ç»„åˆ†æï¼ŒéªŒè¯äº†å› å­å¯¹æœªæ¥æ”¶ç›Šçš„é¢„æµ‹èƒ½åŠ›ã€‚\n",
        "4. æˆ‘ä»¬åˆ›å»ºäº†å¤šå› å­ç»„åˆï¼Œæé«˜äº†æ•´ä½“é¢„æµ‹æ•ˆæœã€‚\n",
        "5. æˆ‘ä»¬åˆ†æäº†å› å­ICçš„ç¨³å®šæ€§ï¼Œè¯„ä¼°äº†å› å­çš„é•¿æœŸæœ‰æ•ˆæ€§ã€‚\n",
        "\n",
        "è¿™äº›åˆ†æç»“æœå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ„å»ºæ›´æœ‰æ•ˆçš„é‡åŒ–æŠ•èµ„ç­–ç•¥ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è‚¡ç¥¨å› å­åˆ†æå®Œæ•´ç¤ºä¾‹\n",
        "\n",
        "æœ¬ç¬”è®°æœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Alphalens è¿›è¡Œä¸“ä¸šçš„è‚¡ç¥¨å› å­åˆ†æï¼ŒåŒ…æ‹¬ï¼š\n",
        "- ä» Excel æ–‡ä»¶åŠ è½½æ•°æ®\n",
        "- æ„å»ºå’Œæµ‹è¯•è‚¡ç¥¨å› å­\n",
        "- ä½¿ç”¨ Alphalens è¿›è¡Œå› å­åˆ†æ\n",
        "- è§£é‡Šåˆ†æç»“æœ\n",
        "\n",
        "## ç›®å½•\n",
        "1. [ç¯å¢ƒè®¾ç½®å’Œæ•°æ®åŠ è½½](#ç¯å¢ƒè®¾ç½®)\n",
        "2. [æ•°æ®é¢„å¤„ç†](#æ•°æ®é¢„å¤„ç†)\n",
        "3. [å› å­æ„å»º](#å› å­æ„å»º)\n",
        "4. [Alphalens å› å­åˆ†æ](#Alphalenså› å­åˆ†æ)\n",
        "5. [ç»“æœè§£é‡Š](#ç»“æœè§£é‡Š)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. ç¯å¢ƒè®¾ç½®å’Œæ•°æ®åŠ è½½ {#ç¯å¢ƒè®¾ç½®}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'alphalens'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Alphalens ç›¸å…³\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malphalens\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mal\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malphalens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_clean_factor_and_forward_returns\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malphalens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtears\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_full_tear_sheet\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'alphalens'"
          ]
        }
      ],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Alphalens ç›¸å…³\n",
        "import alphalens as al\n",
        "from alphalens.utils import get_clean_factor_and_forward_returns\n",
        "from alphalens.tears import create_full_tear_sheet\n",
        "\n",
        "# è®¾ç½®æ˜¾ç¤ºå’Œè­¦å‘Š\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡å­—ä½“\n",
        "plt.rcParams['axes.unicode_minus'] = False     # è´Ÿå·æ˜¾ç¤º\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(\"ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")\n",
        "print(f\"Alphalens ç‰ˆæœ¬: {al.__version__}\")\n",
        "print(f\"Pandas ç‰ˆæœ¬: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åŠ è½½ Excel æ•°æ®\n",
        "# è¯·å°†æ‚¨çš„ Excel æ–‡ä»¶è·¯å¾„æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
        "excel_file_path = \"./data/å› å­åˆ†ææ¨¡ç‰ˆ.xlsx\"  # ä¿®æ”¹ä¸ºæ‚¨çš„æ–‡ä»¶è·¯å¾„\n",
        "\n",
        "def load_stock_data(file_path):\n",
        "    \"\"\"\n",
        "    ä» Excel æ–‡ä»¶åŠ è½½è‚¡ç¥¨æ•°æ®\n",
        "    æ•°æ®æ ¼å¼ï¼š\n",
        "    - ç¬¬ä¸€åˆ—(Aåˆ—)ï¼šè‚¡ç¥¨ä»£ç \n",
        "    - ç¬¬äºŒåˆ—(Båˆ—)ï¼šæ—¶é—´æˆ³\n",
        "    - åç»­åˆ—(Cåˆ—å¼€å§‹)ï¼šå„ç§å› å­æ•°æ®\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # è¯»å– Excel æ–‡ä»¶\n",
        "        df = pd.read_excel(file_path, header=[0, 1, 2, 3])  # è¯»å–å¤šçº§è¡¨å¤´\n",
        "        print(f\"æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} è¡Œ {len(df.columns)} åˆ—\")\n",
        "        \n",
        "        # è·å–ç¬¬ä¸€è¡Œä½œä¸ºå› å­åç§°\n",
        "        factor_names = []\n",
        "        for col in df.columns:\n",
        "            if isinstance(col, tuple) and len(col) > 0:\n",
        "                factor_names.append(col[0])\n",
        "            else:\n",
        "                factor_names.append(col)\n",
        "                \n",
        "        print(\"\\nå› å­åç§°ï¼š\")\n",
        "        print(factor_names)\n",
        "        \n",
        "        # é‡å‘½ååˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œæ–‡å­—ä½œä¸ºå› å­åç§°\n",
        "        df.columns = factor_names\n",
        "        \n",
        "        print(\"\\næ•°æ®é¢„è§ˆï¼š\")\n",
        "        print(df.head())\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®\")\n",
        "        return create_sample_data()\n",
        "    except Exception as e:\n",
        "        print(f\"åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}\")\n",
        "        print(\"ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®\")\n",
        "        return create_sample_data()\n",
        "\n",
        "def create_sample_data():\n",
        "    \"\"\"\n",
        "    åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæ¼”ç¤º\n",
        "    \"\"\"\n",
        "    # åˆ›å»ºæ—¥æœŸèŒƒå›´\n",
        "    dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n",
        "    \n",
        "    # åˆ›å»ºè‚¡ç¥¨ä»£ç \n",
        "    stocks = ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']\n",
        "    \n",
        "    # æ¨¡æ‹Ÿå› å­åç§°ï¼Œä¸å›¾ç‰‡ä¸­çš„åˆ—åä¸€è‡´\n",
        "    factor_names = [\n",
        "        'è‚¡ç¥¨ä»£ç ', 'æ—¶é—´', \n",
        "        'å‰æ”¶ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æˆäº¤é¢', 'æˆäº¤ç¬”æ•°', 'æ¶¨è·Œ',\n",
        "        'RSIç›¸å¯¹å¼ºå¼±æŒ‡æ ‡', 'MACDæŒ‡æ•°å¹³æ»‘ç§»åŠ¨å¹³å‡', 'MAç®€å•ç§»åŠ¨å¹³å‡', 'MAç®€å•ç§»åŠ¨å¹³å‡',\n",
        "        'MTMåŠ¨åŠ›æŒ‡æ ‡', 'ROCå˜åŠ¨é€Ÿç‡', 'RCå˜åŒ–ç‡æŒ‡æ•°', 'PVTé‡ä»·è¶‹åŠ¿æŒ‡æ ‡', \n",
        "        'PRICEOSCä»·æ ¼æŒ¯è¡æŒ‡æ ‡', 'ADTMåŠ¨æ€ä¹°å–æ°”æŒ‡æ ‡', 'ATRçœŸå®æ³¢å¹…', 'BBIå¤šç©ºæŒ‡æ•°', 'BBIBOLLå¤šç©ºå¸ƒæ—çº¿'\n",
        "    ]\n",
        "    \n",
        "    data = []\n",
        "    \n",
        "    for date in dates:\n",
        "        for stock in stocks:\n",
        "            # æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®\n",
        "            price = 10 + np.random.randn() * 2\n",
        "            volume = np.random.randint(1000, 10000)\n",
        "            \n",
        "            row_data = {\n",
        "                'è‚¡ç¥¨ä»£ç ': stock,\n",
        "                'æ—¶é—´': date,\n",
        "                'å‰æ”¶ç›˜ä»·': price - np.random.randn() * 0.1,\n",
        "                'æ”¶ç›˜ä»·': price,\n",
        "                'æœ€é«˜ä»·': price + abs(np.random.randn()) * 0.2,\n",
        "                'æœ€ä½ä»·': price - abs(np.random.randn()) * 0.2,\n",
        "                'æˆäº¤é¢': volume * price,\n",
        "                'æˆäº¤ç¬”æ•°': np.random.randint(100, 1000),\n",
        "                'æ¶¨è·Œ': np.random.randn() * 0.05,\n",
        "                'RSIç›¸å¯¹å¼ºå¼±æŒ‡æ ‡': 50 + np.random.randn() * 10,\n",
        "                'MACDæŒ‡æ•°å¹³æ»‘ç§»åŠ¨å¹³å‡': np.random.randn() * 0.5,\n",
        "                'MAç®€å•ç§»åŠ¨å¹³å‡': price + np.random.randn() * 0.3,\n",
        "                'MTMåŠ¨åŠ›æŒ‡æ ‡': np.random.randn() * 2,\n",
        "                'ROCå˜åŠ¨é€Ÿç‡': np.random.randn() * 5,\n",
        "                'RCå˜åŒ–ç‡æŒ‡æ•°': np.random.randn() * 3,\n",
        "                'PVTé‡ä»·è¶‹åŠ¿æŒ‡æ ‡': volume * np.random.randn(),\n",
        "                'PRICEOSCä»·æ ¼æŒ¯è¡æŒ‡æ ‡': np.random.randn() * 2,\n",
        "                'ADTMåŠ¨æ€ä¹°å–æ°”æŒ‡æ ‡': np.random.randn() * 0.8,\n",
        "                'ATRçœŸå®æ³¢å¹…': abs(np.random.randn()) * 0.3,\n",
        "                'BBIå¤šç©ºæŒ‡æ•°': price + np.random.randn() * 0.2,\n",
        "                'BBIBOLLå¤šç©ºå¸ƒæ—çº¿': price + np.random.randn() * 0.4\n",
        "            }\n",
        "            data.append(row_data)\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"åˆ›å»ºäº†æ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º\")\n",
        "    return df\n",
        "\n",
        "# åŠ è½½æ•°æ®\n",
        "raw_data = load_stock_data(excel_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. æ•°æ®é¢„å¤„ç† {#æ•°æ®é¢„å¤„ç†}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    æ•°æ®é¢„å¤„ç†å‡½æ•°\n",
        "    \"\"\"\n",
        "    # å¤åˆ¶æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®\n",
        "    data = df.copy()\n",
        "    \n",
        "    # ç¡®ä¿æ—¶é—´åˆ—æ˜¯ datetime ç±»å‹\n",
        "    time_col = 'æ—¶é—´'\n",
        "    stock_col = 'è‚¡ç¥¨ä»£ç '\n",
        "    \n",
        "    if time_col in data.columns:\n",
        "        data[time_col] = pd.to_datetime(data[time_col])\n",
        "    else:\n",
        "        # å‡è®¾ç¬¬äºŒåˆ—æ˜¯æ—¶é—´\n",
        "        data.rename(columns={data.columns[1]: time_col}, inplace=True)\n",
        "        data[time_col] = pd.to_datetime(data[time_col])\n",
        "    \n",
        "    # ç¡®ä¿æœ‰è‚¡ç¥¨ä»£ç åˆ—\n",
        "    if stock_col not in data.columns:\n",
        "        # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯è‚¡ç¥¨ä»£ç \n",
        "        data.rename(columns={data.columns[0]: stock_col}, inplace=True)\n",
        "    \n",
        "    # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰\n",
        "    if 'æ¶¨è·Œå¹…' not in data.columns and 'æ”¶ç›˜ä»·' in data.columns and 'å‰æ”¶ç›˜ä»·' in data.columns:\n",
        "        data['æ¶¨è·Œå¹…'] = (data['æ”¶ç›˜ä»·'] / data['å‰æ”¶ç›˜ä»·'] - 1) * 100\n",
        "        print(\"è®¡ç®—äº†æ¶¨è·Œå¹…å› å­\")\n",
        "    \n",
        "    # è®¾ç½®å¤šé‡ç´¢å¼•\n",
        "    data = data.set_index([time_col, stock_col])\n",
        "    \n",
        "    # åˆ é™¤ç¼ºå¤±å€¼è¿‡å¤šçš„åˆ—\n",
        "    data = data.dropna(axis=1, thresh=len(data)*0.5)\n",
        "    \n",
        "    # å¡«å……ç¼ºå¤±å€¼\n",
        "    data = data.fillna(method='ffill').fillna(method='bfill')\n",
        "    \n",
        "    print(f\"é¢„å¤„ç†åæ•°æ®å½¢çŠ¶: {data.shape}\")\n",
        "    print(f\"æ—¶é—´èŒƒå›´: {data.index.get_level_values(time_col).min()} åˆ° {data.index.get_level_values(time_col).max()}\")\n",
        "    print(f\"è‚¡ç¥¨æ•°é‡: {len(data.index.get_level_values(stock_col).unique())}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# é¢„å¤„ç†æ•°æ®\n",
        "processed_data = preprocess_data(raw_data)\n",
        "processed_data.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. å› å­æ„å»º {#å› å­æ„å»º}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_future_returns(data, periods=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    è®¡ç®—æœªæ¥æ”¶ç›Šç‡\n",
        "    \"\"\"\n",
        "    # ç¡®å®šä»·æ ¼åˆ—å’Œè‚¡ç¥¨ä»£ç åˆ—\n",
        "    price_col = 'æ”¶ç›˜ä»·' if 'æ”¶ç›˜ä»·' in data.columns else None\n",
        "    target_col = 'æ¶¨è·Œ' if 'æ¶¨è·Œ' in data.columns else None\n",
        "    stock_col = 'è‚¡ç¥¨ä»£ç '\n",
        "    \n",
        "    if not price_col:\n",
        "        print(\"è­¦å‘Š: æœªæ‰¾åˆ°æ”¶ç›˜ä»·åˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—\")\n",
        "        price_col = data.select_dtypes(include=[np.number]).columns[0]\n",
        "    \n",
        "    returns = pd.DataFrame(index=data.index)\n",
        "    \n",
        "    def forward_returns(group):\n",
        "        \"\"\"è®¡ç®—ä¸ªè‚¡çš„æœªæ¥æ”¶ç›Šç‡\"\"\"\n",
        "        stock_returns = pd.DataFrame(index=group.index)\n",
        "        \n",
        "        for period in periods:\n",
        "            # è®¡ç®—æœªæ¥ period å¤©çš„æ”¶ç›Šç‡\n",
        "            future_price = group[price_col].shift(-period)\n",
        "            stock_returns[f'{period}D'] = (future_price / group[price_col] - 1) * 100  # è½¬ä¸ºç™¾åˆ†æ¯”\n",
        "        \n",
        "        # å¦‚æœæœ‰æ¶¨è·Œåˆ—ï¼Œç›´æ¥ä½¿ç”¨\n",
        "        if target_col:\n",
        "            stock_returns['1D_actual'] = group[target_col]\n",
        "            \n",
        "        return stock_returns\n",
        "    \n",
        "    # ä½¿ç”¨æ­£ç¡®çš„åˆ†ç»„é”®\n",
        "    returns = data.groupby(level=stock_col).apply(forward_returns).droplevel(0)\n",
        "    \n",
        "    print(f\"è®¡ç®—äº† {periods} å¤©çš„æœªæ¥æ”¶ç›Šç‡\")\n",
        "    print(f\"æ”¶ç›Šç‡æ•°æ®å½¢çŠ¶: {returns.shape}\")\n",
        "    \n",
        "    return returns\n",
        "\n",
        "# è®¡ç®—æœªæ¥æ”¶ç›Šç‡\n",
        "forward_returns = calculate_future_returns(processed_data)\n",
        "forward_returns.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_technical_factors(data):\n",
        "    \"\"\"\n",
        "    è®¡ç®—æŠ€æœ¯åˆ†æå› å­\n",
        "    \"\"\"\n",
        "    factors = pd.DataFrame(index=data.index)\n",
        "    \n",
        "    # ç¡®ä¿æˆ‘ä»¬æœ‰åŸºæœ¬çš„ä»·æ ¼æ•°æ®\n",
        "    if 'close' in data.columns:\n",
        "        price_col = 'close'\n",
        "    else:\n",
        "        # å¦‚æœæ²¡æœ‰ close åˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—ä½œä¸ºä»·æ ¼\n",
        "        price_col = data.select_dtypes(include=[np.number]).columns[0]\n",
        "    \n",
        "    if 'volume' in data.columns:\n",
        "        volume_col = 'volume'\n",
        "    else:\n",
        "        # å¦‚æœæ²¡æœ‰ volume åˆ—ï¼Œå°è¯•æ‰¾åˆ°ç›¸å…³åˆ—\n",
        "        volume_candidates = [col for col in data.columns if 'vol' in col.lower()]\n",
        "        volume_col = volume_candidates[0] if volume_candidates else None\n",
        "    \n",
        "    print(f\"ä½¿ç”¨ä»·æ ¼åˆ—: {price_col}\")\n",
        "    print(f\"ä½¿ç”¨æˆäº¤é‡åˆ—: {volume_col}\")\n",
        "    \n",
        "    # 1. åŠ¨é‡å› å­\n",
        "    def momentum_factor(group):\n",
        "        \"\"\"è®¡ç®—åŠ¨é‡å› å­ï¼ˆè¿‡å»20æ—¥æ”¶ç›Šç‡ï¼‰\"\"\"\n",
        "        if len(group) < 21:\n",
        "            return pd.Series(index=group.index, dtype=float)\n",
        "        return group[price_col].pct_change(20)\n",
        "    \n",
        "    factors['momentum_20d'] = (processed_data.groupby('code')\n",
        "                              .apply(momentum_factor)\n",
        "                              .droplevel(0))\n",
        "    \n",
        "    # 2. åè½¬å› å­\n",
        "    def reversal_factor(group):\n",
        "        \"\"\"è®¡ç®—åè½¬å› å­ï¼ˆè¿‡å»5æ—¥æ”¶ç›Šç‡çš„è´Ÿå€¼ï¼‰\"\"\"\n",
        "        if len(group) < 6:\n",
        "            return pd.Series(index=group.index, dtype=float)\n",
        "        return -group[price_col].pct_change(5)\n",
        "    \n",
        "    factors['reversal_5d'] = (processed_data.groupby('code')\n",
        "                             .apply(reversal_factor)\n",
        "                             .droplevel(0))\n",
        "    \n",
        "    # 3. æ³¢åŠ¨ç‡å› å­\n",
        "    def volatility_factor(group):\n",
        "        \"\"\"è®¡ç®—æ³¢åŠ¨ç‡å› å­ï¼ˆè¿‡å»20æ—¥æ”¶ç›Šç‡æ ‡å‡†å·®ï¼‰\"\"\"\n",
        "        if len(group) < 21:\n",
        "            return pd.Series(index=group.index, dtype=float)\n",
        "        returns = group[price_col].pct_change()\n",
        "        return returns.rolling(20).std()\n",
        "    \n",
        "    factors['volatility_20d'] = (processed_data.groupby('code')\n",
        "                                .apply(volatility_factor)\n",
        "                                .droplevel(0))\n",
        "    \n",
        "    # 4. æˆäº¤é‡å› å­ï¼ˆå¦‚æœæœ‰æˆäº¤é‡æ•°æ®ï¼‰\n",
        "    if volume_col:\n",
        "        def volume_factor(group):\n",
        "            \"\"\"è®¡ç®—æˆäº¤é‡å› å­ï¼ˆè¿‡å»20æ—¥å¹³å‡æˆäº¤é‡æ¯”ç‡ï¼‰\"\"\"\n",
        "            if len(group) < 21:\n",
        "                return pd.Series(index=group.index, dtype=float)\n",
        "            avg_volume = group[volume_col].rolling(20).mean()\n",
        "            return group[volume_col] / avg_volume\n",
        "        \n",
        "        factors['volume_ratio_20d'] = (processed_data.groupby('code')\n",
        "                                     .apply(volume_factor)\n",
        "                                     .droplevel(0))\n",
        "    \n",
        "    # 5. ä»·å€¼å› å­ï¼ˆå¦‚æœæœ‰ç›¸å…³æ•°æ®ï¼‰\n",
        "    if 'pe_ratio' in data.columns:\n",
        "        factors['pe_factor'] = -data['pe_ratio']  # PE è¶Šä½è¶Šå¥½ï¼Œæ‰€ä»¥å–è´Ÿå€¼\n",
        "    \n",
        "    if 'pb_ratio' in data.columns:\n",
        "        factors['pb_factor'] = -data['pb_ratio']  # PB è¶Šä½è¶Šå¥½ï¼Œæ‰€ä»¥å–è´Ÿå€¼\n",
        "    \n",
        "    # åˆ é™¤ç¼ºå¤±å€¼\n",
        "    factors = factors.dropna()\n",
        "    \n",
        "    print(f\"\\nè®¡ç®—å‡º {len(factors.columns)} ä¸ªå› å­ï¼š\")\n",
        "    print(factors.columns.tolist())\n",
        "    print(f\"å› å­æ•°æ®å½¢çŠ¶: {factors.shape}\")\n",
        "    \n",
        "    return factors\n",
        "\n",
        "# è®¡ç®—å› å­\n",
        "factor_data = calculate_technical_factors(processed_data)\n",
        "factor_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Alphalens å› å­åˆ†æ {#Alphalenså› å­åˆ†æ}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_factors_ic(factor_data, forward_returns):\n",
        "    \"\"\"\n",
        "    è®¡ç®—å› å­ICå€¼ï¼ˆä¿¡æ¯ç³»æ•°ï¼‰\n",
        "    \"\"\"\n",
        "    print(\"å¼€å§‹è®¡ç®—å› å­ICå€¼...\")\n",
        "    \n",
        "    # ç¡®ä¿ç´¢å¼•ä¸€è‡´\n",
        "    common_index = factor_data.index.intersection(forward_returns.index)\n",
        "    factors = factor_data.loc[common_index]\n",
        "    returns = forward_returns.loc[common_index]\n",
        "    \n",
        "    # åˆ›å»ºç»“æœDataFrame\n",
        "    ic_results = pd.DataFrame(\n",
        "        index=factor_data.columns,\n",
        "        columns=['IC_1D', 'IC_5D', 'IC_10D', 'IC_Rank_1D', 'IC_Rank_5D', 'IC_Rank_10D']\n",
        "    )\n",
        "    \n",
        "    # è®¡ç®—æ¯ä¸ªå› å­çš„ICå€¼\n",
        "    for factor_name in factors.columns:\n",
        "        factor_series = factors[factor_name].dropna()\n",
        "        \n",
        "        # å¯¹äºæ¯ä¸ªé¢„æµ‹æœŸ\n",
        "        for period in ['1D', '5D', '10D']:\n",
        "            if period in returns.columns:\n",
        "                return_series = returns[period].dropna()\n",
        "                \n",
        "                # ç¡®ä¿æ•°æ®å¯¹é½\n",
        "                common_idx = factor_series.index.intersection(return_series.index)\n",
        "                if len(common_idx) > 0:\n",
        "                    f = factor_series.loc[common_idx]\n",
        "                    r = return_series.loc[common_idx]\n",
        "                    \n",
        "                    # è®¡ç®—Pearsonç›¸å…³ç³»æ•°ï¼ˆçº¿æ€§ICï¼‰\n",
        "                    ic = f.corr(r)\n",
        "                    ic_results.loc[factor_name, f'IC_{period}'] = ic\n",
        "                    \n",
        "                    # è®¡ç®—Spearmanç§©ç›¸å…³ç³»æ•°ï¼ˆç§©ICï¼‰\n",
        "                    rank_ic = f.corr(r, method='spearman')\n",
        "                    ic_results.loc[factor_name, f'IC_Rank_{period}'] = rank_ic\n",
        "    \n",
        "    # æŒ‰1æ—¥ICç»å¯¹å€¼æ’åº\n",
        "    ic_results = ic_results.sort_values('IC_1D', key=abs, ascending=False)\n",
        "    \n",
        "    print(\"å› å­ICè®¡ç®—å®Œæˆï¼\")\n",
        "    return ic_results\n",
        "\n",
        "# è®¡ç®—å› å­IC\n",
        "ic_results = analyze_factors_ic(factor_data, forward_returns)\n",
        "ic_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_ic_results(ic_results):\n",
        "    \"\"\"\n",
        "    å¯è§†åŒ–å› å­ICç»“æœ\n",
        "    \"\"\"\n",
        "    # è®¾ç½®å›¾è¡¨å¤§å°\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    \n",
        "    # é€‰æ‹©å‰10ä¸ªå› å­\n",
        "    top_factors = ic_results.head(10).index\n",
        "    \n",
        "    # ç»˜åˆ¶1æ—¥ICæŸ±çŠ¶å›¾\n",
        "    plt.subplot(1, 2, 1)\n",
        "    ic_1d = ic_results.loc[top_factors, 'IC_1D'].sort_values()\n",
        "    bars = plt.barh(ic_1d.index, ic_1d.values, color=['r' if x < 0 else 'g' for x in ic_1d.values])\n",
        "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.title('å‰10ä¸ªå› å­çš„1æ—¥ICå€¼', fontsize=12)\n",
        "    plt.xlabel('ICå€¼')\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
        "    \n",
        "    # ä¸ºæ¯ä¸ªæŸ±çŠ¶å›¾æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
        "    for bar in bars:\n",
        "        width = bar.get_width()\n",
        "        label_x_pos = width if width > 0 else width - 0.03\n",
        "        plt.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.4f}', \n",
        "                 va='center', ha='left' if width > 0 else 'right', fontsize=9)\n",
        "    \n",
        "    # ç»˜åˆ¶5æ—¥ICæŸ±çŠ¶å›¾\n",
        "    plt.subplot(1, 2, 2)\n",
        "    ic_5d = ic_results.loc[top_factors, 'IC_5D'].sort_values()\n",
        "    bars = plt.barh(ic_5d.index, ic_5d.values, color=['r' if x < 0 else 'g' for x in ic_5d.values])\n",
        "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.title('å‰10ä¸ªå› å­çš„5æ—¥ICå€¼', fontsize=12)\n",
        "    plt.xlabel('ICå€¼')\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
        "    \n",
        "    # ä¸ºæ¯ä¸ªæŸ±çŠ¶å›¾æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
        "    for bar in bars:\n",
        "        width = bar.get_width()\n",
        "        label_x_pos = width if width > 0 else width - 0.03\n",
        "        plt.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.4f}', \n",
        "                 va='center', ha='left' if width > 0 else 'right', fontsize=9)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# å¯è§†åŒ–ICç»“æœ\n",
        "visualize_ic_results(ic_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_factor_with_alphalens(factor_data, forward_returns, factor_name):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨Alphalensè¿›è¡Œå•å› å­åˆ†æ\n",
        "    \"\"\"\n",
        "    print(f\"ä½¿ç”¨Alphalensåˆ†æå› å­: {factor_name}\")\n",
        "    \n",
        "    # è·å–å› å­æ•°æ®\n",
        "    factor_series = factor_data[factor_name]\n",
        "    \n",
        "    # è·å–ä»·æ ¼æ•°æ®ï¼ˆç”¨äºAlphalensï¼‰\n",
        "    if 'æ”¶ç›˜ä»·' in processed_data.columns:\n",
        "        price_series = processed_data['æ”¶ç›˜ä»·']\n",
        "    else:\n",
        "        price_series = processed_data.select_dtypes(include=[np.number]).columns[0]\n",
        "        price_series = processed_data[price_series]\n",
        "    \n",
        "    try:\n",
        "        # å‡†å¤‡Alphalensæ ¼å¼çš„æ•°æ®\n",
        "        factor_data_clean = get_clean_factor_and_forward_returns(\n",
        "            factor=factor_series,\n",
        "            prices=price_series,\n",
        "            periods=(1, 5, 10),\n",
        "            quantiles=5,\n",
        "            binning_by_group=False,\n",
        "            max_loss=0.35\n",
        "        )\n",
        "        \n",
        "        print(\"Alphalensæ•°æ®å‡†å¤‡å®Œæˆï¼Œç”Ÿæˆåˆ†ææŠ¥å‘Š...\")\n",
        "        \n",
        "        # åˆ›å»ºå®Œæ•´çš„å› å­åˆ†ææŠ¥å‘Š\n",
        "        create_full_tear_sheet(factor_data_clean)\n",
        "        \n",
        "        return factor_data_clean\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Alphalensåˆ†æå‡ºé”™: {e}\")\n",
        "        print(\"å°è¯•æ‰‹åŠ¨è®¡ç®—åˆ†ä½æ•°æ”¶ç›Š...\")\n",
        "        \n",
        "        # æ‰‹åŠ¨è®¡ç®—åˆ†ä½æ•°æ”¶ç›Š\n",
        "        factor_quantiles = pd.qcut(factor_series, 5, labels=False) + 1\n",
        "        \n",
        "        # åˆå¹¶å› å­åˆ†ä½æ•°å’Œæ”¶ç›Šç‡\n",
        "        combined = pd.DataFrame({\n",
        "            'factor': factor_series,\n",
        "            'quantile': factor_quantiles,\n",
        "            'return_1d': forward_returns['1D']\n",
        "        }).dropna()\n",
        "        \n",
        "        # è®¡ç®—å„åˆ†ä½æ•°çš„å¹³å‡æ”¶ç›Š\n",
        "        quantile_returns = combined.groupby('quantile')['return_1d'].mean()\n",
        "        \n",
        "        # ç»˜åˆ¶åˆ†ä½æ•°æ”¶ç›Šå›¾\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        quantile_returns.plot(kind='bar', color='skyblue')\n",
        "        plt.title(f'{factor_name} å› å­åˆ†ä½æ•°æ”¶ç›Š')\n",
        "        plt.xlabel('åˆ†ä½æ•°')\n",
        "        plt.ylabel('å¹³å‡æ”¶ç›Šç‡ (%)')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "        plt.show()\n",
        "        \n",
        "        return quantile_returns\n",
        "\n",
        "# é€‰æ‹©ICå€¼æœ€é«˜çš„å› å­è¿›è¡ŒAlphalensåˆ†æ\n",
        "if not ic_results.empty:\n",
        "    top_factor = ic_results.index[0]\n",
        "    print(f\"é€‰æ‹©ICå€¼æœ€é«˜çš„å› å­è¿›è¡Œè¯¦ç»†åˆ†æ: {top_factor}\")\n",
        "    alphalens_result = analyze_factor_with_alphalens(factor_data, forward_returns, top_factor)\n",
        "else:\n",
        "    print(\"æ²¡æœ‰æœ‰æ•ˆçš„å› å­ICç»“æœ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. ç»“æœè§£é‡Š {#ç»“æœè§£é‡Š}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def interpret_ic_results(ic_results):\n",
        "    \"\"\"\n",
        "    è§£é‡ŠICç»“æœ\n",
        "    \"\"\"\n",
        "    print(\"å› å­ICåˆ†æç»“æœè§£é‡Š:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # ç­›é€‰æœ‰æ•ˆçš„å› å­ï¼ˆICå€¼ä¸ä¸ºNaNï¼‰\n",
        "    valid_factors = ic_results.dropna(subset=['IC_1D'])\n",
        "    \n",
        "    if valid_factors.empty:\n",
        "        print(\"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å› å­ICç»“æœ\")\n",
        "        return\n",
        "    \n",
        "    # 1. æœ€ä½³å› å­\n",
        "    best_factor = valid_factors.iloc[0].name\n",
        "    best_ic = valid_factors.iloc[0]['IC_1D']\n",
        "    best_rank_ic = valid_factors.iloc[0]['IC_Rank_1D']\n",
        "    \n",
        "    print(f\"1. æœ€ä½³å› å­: {best_factor}\")\n",
        "    print(f\"   - 1æ—¥ICå€¼: {best_ic:.4f}\")\n",
        "    print(f\"   - 1æ—¥ç§©ICå€¼: {best_rank_ic:.4f}\")\n",
        "    \n",
        "    # è¯„ä¼°ICå€¼\n",
        "    if abs(best_ic) > 0.05:\n",
        "        print(\"   - è¯„ä»·: ğŸ† ä¼˜ç§€ (|IC| > 0.05)\")\n",
        "    elif abs(best_ic) > 0.02:\n",
        "        print(\"   - è¯„ä»·: ğŸ‘ è‰¯å¥½ (|IC| > 0.02)\")\n",
        "    else:\n",
        "        print(\"   - è¯„ä»·: âš ï¸ ä¸€èˆ¬ (|IC| < 0.02)\")\n",
        "    \n",
        "    # 2. å› å­ç¨³å®šæ€§åˆ†æ\n",
        "    print(\"\\n2. å› å­ç¨³å®šæ€§åˆ†æ:\")\n",
        "    for i, (factor, row) in enumerate(valid_factors.head(5).iterrows()):\n",
        "        ic_1d = row['IC_1D']\n",
        "        ic_5d = row['IC_5D']\n",
        "        ic_10d = row['IC_10D'] if 'IC_10D' in row and not pd.isna(row['IC_10D']) else None\n",
        "        \n",
        "        print(f\"   {i+1}. {factor}:\")\n",
        "        print(f\"      - 1æ—¥IC: {ic_1d:.4f}\")\n",
        "        print(f\"      - 5æ—¥IC: {ic_5d:.4f}\")\n",
        "        if ic_10d is not None:\n",
        "            print(f\"      - 10æ—¥IC: {ic_10d:.4f}\")\n",
        "        \n",
        "        # åˆ¤æ–­å› å­ç¨³å®šæ€§\n",
        "        if ic_5d is not None and not pd.isna(ic_5d):\n",
        "            if np.sign(ic_1d) == np.sign(ic_5d) and abs(ic_5d) > 0.01:\n",
        "                print(\"      - ç¨³å®šæ€§: âœ“ è‰¯å¥½ (é¢„æµ‹æ–¹å‘ä¸€è‡´)\")\n",
        "            else:\n",
        "                print(\"      - ç¨³å®šæ€§: âœ— ä¸ç¨³å®š (é¢„æµ‹æ–¹å‘ä¸ä¸€è‡´æˆ–è¡°å‡å¿«)\")\n",
        "    \n",
        "    # 3. æŠ•èµ„å»ºè®®\n",
        "    print(\"\\n3. æŠ•èµ„å»ºè®®:\")\n",
        "    top_positive = valid_factors[valid_factors['IC_1D'] > 0].head(3)\n",
        "    top_negative = valid_factors[valid_factors['IC_1D'] < 0].head(3)\n",
        "    \n",
        "    if not top_positive.empty:\n",
        "        print(\"   åšå¤šç­–ç•¥:\")\n",
        "        for factor, row in top_positive.iterrows():\n",
        "            print(f\"   - é€‰æ‹© {factor} å› å­å€¼è¾ƒé«˜çš„è‚¡ç¥¨ (IC={row['IC_1D']:.4f})\")\n",
        "    \n",
        "    if not top_negative.empty:\n",
        "        print(\"   åšç©ºç­–ç•¥:\")\n",
        "        for factor, row in top_negative.iterrows():\n",
        "            print(f\"   - é€‰æ‹© {factor} å› å­å€¼è¾ƒä½çš„è‚¡ç¥¨ (IC={row['IC_1D']:.4f})\")\n",
        "    \n",
        "    # 4. ç»¼åˆè¯„ä»·\n",
        "    print(\"\\n4. ç»¼åˆè¯„ä»·:\")\n",
        "    avg_abs_ic = valid_factors['IC_1D'].abs().mean()\n",
        "    \n",
        "    if avg_abs_ic > 0.03:\n",
        "        print(f\"   æ•´ä½“é¢„æµ‹èƒ½åŠ›: ğŸ‘ è‰¯å¥½ (å¹³å‡|IC|={avg_abs_ic:.4f})\")\n",
        "    else:\n",
        "        print(f\"   æ•´ä½“é¢„æµ‹èƒ½åŠ›: âš ï¸ ä¸€èˆ¬ (å¹³å‡|IC|={avg_abs_ic:.4f})\")\n",
        "    \n",
        "    # å»ºè®®ä½¿ç”¨çš„å› å­ç»„åˆ\n",
        "    print(\"\\n5. å»ºè®®ä½¿ç”¨çš„å› å­ç»„åˆ:\")\n",
        "    \n",
        "    # é€‰æ‹©ICç»å¯¹å€¼å¤§äº0.02çš„å› å­\n",
        "    good_factors = valid_factors[valid_factors['IC_1D'].abs() > 0.02]\n",
        "    if not good_factors.empty:\n",
        "        print(f\"   æ¨èä½¿ç”¨ä»¥ä¸‹ {len(good_factors)} ä¸ªå› å­æ„å»ºå¤šå› å­æ¨¡å‹:\")\n",
        "        for factor, row in good_factors.iterrows():\n",
        "            direction = \"æ­£å‘\" if row['IC_1D'] > 0 else \"åå‘\"\n",
        "            print(f\"   - {factor}: {direction} (IC={row['IC_1D']:.4f})\")\n",
        "    else:\n",
        "        print(\"   æ²¡æœ‰æ‰¾åˆ°é¢„æµ‹èƒ½åŠ›è¶³å¤Ÿå¼ºçš„å› å­ï¼Œå»ºè®®å°è¯•å…¶ä»–å› å­æˆ–ç»„åˆæ–¹æ³•\")\n",
        "\n",
        "# è§£é‡ŠICç»“æœ\n",
        "interpret_ic_results(ic_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_multi_factor_model(factor_data, forward_returns, ic_results, threshold=0.02):\n",
        "    \"\"\"\n",
        "    åˆ›å»ºç®€å•çš„å¤šå› å­æ¨¡å‹\n",
        "    \"\"\"\n",
        "    print(\"åˆ›å»ºå¤šå› å­æ¨¡å‹...\")\n",
        "    \n",
        "    # é€‰æ‹©ICç»å¯¹å€¼å¤§äºé˜ˆå€¼çš„å› å­\n",
        "    good_factors = ic_results[ic_results['IC_1D'].abs() > threshold].index.tolist()\n",
        "    \n",
        "    if not good_factors:\n",
        "        print(\"æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿå¼ºçš„å› å­ï¼Œé™ä½é˜ˆå€¼é‡è¯•\")\n",
        "        threshold = 0.01\n",
        "        good_factors = ic_results[ic_results['IC_1D'].abs() > threshold].index.tolist()\n",
        "    \n",
        "    if not good_factors:\n",
        "        print(\"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å› å­ï¼Œæ— æ³•åˆ›å»ºå¤šå› å­æ¨¡å‹\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"é€‰æ‹©äº† {len(good_factors)} ä¸ªå› å­: {good_factors}\")\n",
        "    \n",
        "    # ç¡®ä¿ç´¢å¼•ä¸€è‡´\n",
        "    common_index = factor_data.index.intersection(forward_returns.index)\n",
        "    selected_factors = factor_data.loc[common_index, good_factors]\n",
        "    returns = forward_returns.loc[common_index, '1D']\n",
        "    \n",
        "    # åˆ›å»ºå¤šå› å­å¾—åˆ†\n",
        "    scores = pd.DataFrame(index=selected_factors.index)\n",
        "    \n",
        "    # æ ¹æ®ICç¬¦å·ç¡®å®šå› å­æ–¹å‘\n",
        "    for factor in good_factors:\n",
        "        ic = ic_results.loc[factor, 'IC_1D']\n",
        "        # å¦‚æœICä¸ºæ­£ï¼Œå› å­å€¼è¶Šå¤§è¶Šå¥½ï¼›å¦‚æœICä¸ºè´Ÿï¼Œå› å­å€¼è¶Šå°è¶Šå¥½\n",
        "        direction = np.sign(ic)\n",
        "        scores[factor] = selected_factors[factor] * direction\n",
        "    \n",
        "    # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆç®€å•å¹³å‡ï¼‰\n",
        "    scores['total_score'] = scores.mean(axis=1)\n",
        "    \n",
        "    # æŒ‰æ—¥æœŸåˆ†ç»„ï¼Œè®¡ç®—åˆ†ä½æ•°\n",
        "    def calculate_quantiles(group):\n",
        "        return pd.qcut(group['total_score'], 5, labels=False) + 1\n",
        "    \n",
        "    # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—åˆ†ä½æ•°\n",
        "    quantiles = scores.groupby(level=0).apply(\n",
        "        lambda x: pd.Series(calculate_quantiles(x), index=x.index)\n",
        "    ).droplevel(0)\n",
        "    \n",
        "    scores['quantile'] = quantiles\n",
        "    \n",
        "    # åˆå¹¶å¾—åˆ†å’Œæ”¶ç›Šç‡\n",
        "    result = pd.DataFrame({\n",
        "        'score': scores['total_score'],\n",
        "        'quantile': scores['quantile'],\n",
        "        'return': returns\n",
        "    })\n",
        "    \n",
        "    # è®¡ç®—å„åˆ†ä½æ•°çš„å¹³å‡æ”¶ç›Š\n",
        "    quantile_returns = result.groupby('quantile')['return'].mean()\n",
        "    \n",
        "    # è®¡ç®—å¤šç©ºç»„åˆæ”¶ç›Š\n",
        "    long_short_return = quantile_returns.iloc[-1] - quantile_returns.iloc[0]\n",
        "    \n",
        "    print(f\"\\nå„åˆ†ä½æ•°å¹³å‡æ”¶ç›Š:\")\n",
        "    for q, ret in quantile_returns.items():\n",
        "        print(f\"åˆ†ä½æ•° {q}: {ret:.4f}%\")\n",
        "    \n",
        "    print(f\"\\nå¤šç©ºç»„åˆæ”¶ç›Š: {long_short_return:.4f}%\")\n",
        "    \n",
        "    # ç»˜åˆ¶åˆ†ä½æ•°æ”¶ç›Šå›¾\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    quantile_returns.plot(kind='bar', color='skyblue')\n",
        "    plt.title('å¤šå› å­æ¨¡å‹åˆ†ä½æ•°æ”¶ç›Š')\n",
        "    plt.xlabel('åˆ†ä½æ•°')\n",
        "    plt.ylabel('å¹³å‡æ”¶ç›Šç‡ (%)')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "    plt.show()\n",
        "    \n",
        "    return result\n",
        "\n",
        "# åˆ›å»ºå¤šå› å­æ¨¡å‹\n",
        "multi_factor_result = create_multi_factor_model(factor_data, forward_returns, ic_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## æ€»ç»“\n",
        "\n",
        "æœ¬ç¬”è®°æœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Excel æ–‡ä»¶ä¸­çš„åˆ—ä½œä¸ºå› å­è¿›è¡Œè‚¡ç¥¨å› å­åˆ†æï¼Œä¸»è¦æ­¥éª¤åŒ…æ‹¬ï¼š\n",
        "\n",
        "1. **æ•°æ®åŠ è½½ä¸é¢„å¤„ç†**ï¼š\n",
        "   - ä» Excel æ–‡ä»¶åŠ è½½æ•°æ®ï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºå› å­åç§°\n",
        "   - è®¾ç½®è‚¡ç¥¨ä»£ç å’Œæ—¶é—´ä¸ºå¤šé‡ç´¢å¼•\n",
        "   - å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼\n",
        "\n",
        "2. **å› å­å‡†å¤‡**ï¼š\n",
        "   - ç›´æ¥ä½¿ç”¨ Excel æ–‡ä»¶ä¸­çš„åˆ—ä½œä¸ºå› å­\n",
        "   - å¯¹å› å­è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†\n",
        "   - è®¡ç®—æœªæ¥æ”¶ç›Šç‡ä½œä¸ºé¢„æµ‹ç›®æ ‡\n",
        "\n",
        "3. **å› å­åˆ†æ**ï¼š\n",
        "   - è®¡ç®—å› å­ IC å€¼ï¼ˆä¿¡æ¯ç³»æ•°ï¼‰\n",
        "   - å¯è§†åŒ–å› å­ IC ç»“æœ\n",
        "   - ä½¿ç”¨ Alphalens è¿›è¡Œè¯¦ç»†åˆ†æ\n",
        "\n",
        "4. **ç»“æœè§£é‡Š**ï¼š\n",
        "   - è¯„ä¼°å› å­é¢„æµ‹èƒ½åŠ›\n",
        "   - åˆ†æå› å­ç¨³å®šæ€§\n",
        "   - æä¾›æŠ•èµ„å»ºè®®\n",
        "\n",
        "5. **å¤šå› å­æ¨¡å‹**ï¼š\n",
        "   - é€‰æ‹© IC å€¼è¾ƒé«˜çš„å› å­æ„å»ºæ¨¡å‹\n",
        "   - è®¡ç®—ç»¼åˆå› å­å¾—åˆ†\n",
        "   - åˆ†æåˆ†ä½æ•°æ”¶ç›Šè¡¨ç°\n",
        "\n",
        "### IC å€¼è§£é‡Š\n",
        "\n",
        "ICï¼ˆä¿¡æ¯ç³»æ•°ï¼‰æ˜¯è¡¡é‡å› å­é¢„æµ‹èƒ½åŠ›çš„å…³é”®æŒ‡æ ‡ï¼š\n",
        "\n",
        "- **|IC| > 0.05**ï¼šä¼˜ç§€å› å­ï¼Œé¢„æµ‹èƒ½åŠ›å¼º\n",
        "- **0.02 < |IC| < 0.05**ï¼šè‰¯å¥½å› å­ï¼Œæœ‰ä¸€å®šé¢„æµ‹èƒ½åŠ›\n",
        "- **|IC| < 0.02**ï¼šä¸€èˆ¬å› å­ï¼Œé¢„æµ‹èƒ½åŠ›è¾ƒå¼±\n",
        "\n",
        "### åç»­ä¼˜åŒ–æ–¹å‘\n",
        "\n",
        "1. **å› å­å¤„ç†**ï¼š\n",
        "   - ä¸­æ€§åŒ–å¤„ç†ï¼ˆè¡Œä¸šã€å¸‚å€¼ä¸­æ€§ï¼‰\n",
        "   - æå€¼å¤„ç†ï¼ˆWinsorizeï¼‰\n",
        "   - å› å­æ­£äº¤åŒ–\n",
        "\n",
        "2. **å¤šå› å­ç»„åˆ**ï¼š\n",
        "   - IC åŠ æƒ\n",
        "   - é£é™©å¹³ä»·\n",
        "   - æœ€å¤§ä¿¡æ¯æ¯”ç‡\n",
        "\n",
        "3. **å›æµ‹éªŒè¯**ï¼š\n",
        "   - åŠ å…¥äº¤æ˜“æˆæœ¬\n",
        "   - è€ƒè™‘æµåŠ¨æ€§çº¦æŸ\n",
        "   - è®¾è®¡å®Œæ•´äº¤æ˜“ç­–ç•¥\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
